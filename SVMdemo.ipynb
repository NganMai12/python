{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVMdemo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4QKViA5HMNa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "def make_meshgrid(x, y, h=.02):\n",
        "    x_min, x_max = x.min() - 1, x.max() + 1\n",
        "    y_min, y_max = y.min() - 1, y.max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                         np.arange(y_min, y_max, h))\n",
        "    return xx, yy\n",
        "\n",
        "\n",
        "def plot_contours(ax, clf, xx, yy, **params):\n",
        "\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    out = ax.contourf(xx, yy, Z, **params)\n",
        "    return out\n",
        "\n",
        "\n",
        "# import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "# Take the first two features. We could avoid this by using a two-dim dataset\n",
        "X = iris.data[:, :2]\n",
        "y = iris.target\n",
        "\n",
        "# split train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=50)\n",
        "\n",
        "\n",
        "# we create an instance of SVM and fit out data. We do not scale our\n",
        "# data since we want to plot the support vectors\n",
        "C = 1.0 # SVM regularization parameter\n",
        "models = svm.SVC(kernel='poly', degree=2.0, C=C, gamma='auto')\n",
        "#models = svm.SVC(kernel='rbf', gamma=1000, C=C)\n",
        "#models = svm.SVC(kernel='linear', C=C)\n",
        "\n",
        "clf = models.fit(X, y)\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# title for the plots\n",
        "titles = ('SVC with poly kernel')\n",
        "#titles = ('SVC with rbf kernel')\n",
        "#titles = ('SVC with linear kernel')\n",
        "\n",
        "X0, X1 = X[:, 0], X[:, 1]\n",
        "xx, yy = make_meshgrid(X0, X1)\n",
        "\n",
        "plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
        "ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
        "ax.set_xlabel('Sepal length')\n",
        "ax.set_ylabel('Sepal width')\n",
        "ax.set_xticks(())\n",
        "ax.set_yticks(())\n",
        "ax.set_title(titles)\n",
        "plt.show()\n",
        "\n",
        "models.fit(X_train, y_train)\n",
        "y_pred = models.predict(X_test)\n",
        "print(\"Accuracy: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))\n",
        "print(\"Precision Score: %.2f %%\" %  (100*precision_score(y_test,y_pred, average='macro')))\n",
        "print(\"Recall Score: %.2f %%\" %  (100*recall_score(y_test,y_pred, average='macro')))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}